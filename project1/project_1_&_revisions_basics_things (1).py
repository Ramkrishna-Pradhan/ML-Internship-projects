# -*- coding: utf-8 -*-
"""project-1 & revisions_basics_things.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gqmlpMxfHJ5mrw5w1qTEGcXfGgJIpcHs
"""

import datetime
import math
import pandas
import matplotlib as x
import tensorflow
import numpy



x = datetime.datetime.now()
print(x)

a = 64
print(math.sqrt(a))

x = "Developer"
print(x[::-1])

"""**String Concat** (we can't concat string & integer)"""

print("HI" + 5)

print("Hello, we are building \n machine learning projects")

b = {10,20,30}
print(b[0])

if -100:
  print("YES! We have a match!")
  if -100:
    print("YES! We have a match!")
    if -100:
      print("YES! We have a match!")

a = [10,20,30] # List
a = (10,20,30) # Tuple
a = {10,20,30} # Set
a = {"Phy": 10,"Com": 20} # Dict

"""**1. Visualizing Data with Matplotlib**"""

import matplotlib.pyplot as plt
import numpy as np

"""*Line chart: Marks trend over 5 tests*"""

subjects = ["Maths", "DBMS", "OS", "ML", "Python"]
avg_marks = [78, 72, 69, 63, 85]

plt.figure(figsize=(6, 4))
plt.bar(subjects, avg_marks)
plt.title("Average Marks per Subject")
plt.xlabel("Subject")
plt.ylabel("Average Marks")
plt.ylim(0, 100)
plt.grid(axis="y", linestyle="--", alpha=0.4)
plt.show()

"""**Regression: Hours Studied → Marks (Real Use Case)**"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression

hours = np.array([1, 2, 3, 4, 5, 6, 7, 8]).reshape(-1, 1)  # feature
marks = np.array([35, 40, 50, 55, 65, 70, 75, 85])        # target

"""**Visualize raw data**"""

plt.figure(figsize=(6, 4))
plt.scatter(hours, marks)
plt.title("Hours Studied vs Marks")
plt.xlabel("Hours Studied")
plt.ylabel("Marks")
plt.grid(True, linestyle="--", alpha=0.4)
plt.show()

"""**Fit Linear Regression model**"""

model = LinearRegression()
model.fit(hours, marks)

print("Slope (m):", model.coef_[0])
print("Intercept (b):", model.intercept_)

"""This model is learning a line: marks ≈ m * hours + b. **bold text**
In real life, we do this for price prediction, salary prediction, demand forecasting, etc.
"""

hours_new = np.linspace(0, 10, 100).reshape(-1, 1)
pred_marks = model.predict(hours_new)

plt.figure(figsize=(6, 4))
plt.scatter(hours, marks, label="Actual Data")
plt.plot(hours_new, pred_marks, label="Fitted Line", linewidth=2)
plt.title("Linear Regression: Hours vs Marks")
plt.xlabel("Hours Studied")
plt.ylabel("Marks")
plt.legend()
plt.grid(True, linestyle="--", alpha=0.4)
plt.show()

"""**Blue dots = real data.**
**Line** = Models's prediction (**Model's understanding of relation**)
Once trained, model can predict marks for any given inputs (remember it)

**Let's see a prediction**
"""

my_hours = np.array([[5]]) # change this number live (by yourself)
my_pred = model.predict(my_hours)[0]
print(f"If you study {my_hours[0][0]} hours, model predicts ~{my_pred:.2f} marks.")

"""**Classification**: *Iris Flowers + Visualization*"""

# Load dataset

from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
import matplotlib.pyplot as plt
import numpy as np

iris = load_iris()
X = iris.data[:, :2] # use only first 2 features for easy plotting
y = iris.target

feature_names = iris.feature_names[:2]
target_names = iris.target_names

print("Features:", feature_names)
print("Classes:", target_names)

# Plot data by class

plt.figure(figsize=(6, 4))

for class_idx, class_name in enumerate(target_names):
    plt.scatter(
        X[y == class_idx, 0],
        X[y == class_idx, 1],
        label=class_name
    )

plt.xlabel(feature_names[0])
plt.ylabel(feature_names[1])
plt.title("Iris Dataset (2 Features)")
plt.legend()
plt.grid(True, linestyle="--", alpha=0.4)
plt.show()

"""Remember it Must:

This is where unsupervised and supervised can be recalled.
Each color == different flower species

In real world: It is used for customer segmentations, image classes, diesease categories.
"""

# Train a simple KNN classifier

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, y_train)

accuracy = knn.score(X_test, y_test)
print(f"Test Accuracy: {accuracy:.2f}")